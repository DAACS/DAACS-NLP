{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c089a6d-4b47-4c36-87b5-57d55ecffdc5",
   "metadata": {},
   "source": [
    "# This is great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65eb87b9-1146-401c-bad9-aad377ae7375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/13 20:48:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from daacs.infrastructure.bootstrap import Bootstrap\n",
    "from daacs.infrastructure.wgu_file import WGU_File\n",
    "from daacs.infrastructure.essays import Essays\n",
    "from loguru import logger\n",
    "from pyspark.sql.functions import desc, lit, udf, corr, when, lower, col\n",
    "\n",
    "DAACS_ID=\"daacs_id\"\n",
    "b = Bootstrap()\n",
    "spark = b.get_spark() \n",
    "\n",
    "## These are for test and train!! We hae grades for these!! \n",
    "## Load WGU and filter out the records that are in there twice.\n",
    "\n",
    "## use average of two raters? \n",
    "## use the ones where the agree.\n",
    "\n",
    "ratings_columns = ['EssayID', 'TotalScore1', 'TotalScore2', 'TotalScore']\n",
    "wgu_ratings_raw = spark.read.option(\"header\", True)\\\n",
    "    .csv(b.file_url(WGU_File.wgu_ratings))\\\n",
    "    .select(ratings_columns)\\\n",
    "    .withColumnRenamed(\"EssayID\", DAACS_ID)\n",
    "essay_id_counts = wgu_ratings_raw.groupBy(DAACS_ID).count()\n",
    "unique_essay_ids = essay_id_counts.filter(col(\"count\") == 1).select(DAACS_ID)\n",
    "wgu_ratings = wgu_ratings_raw.join(unique_essay_ids, [DAACS_ID])\n",
    "\n",
    "# wgu_ratings.printSchema() \n",
    "# root\n",
    "#  |-- daacs_id: string (nullable = true)\n",
    "#  |-- TotalScore1: string (nullable = true)\n",
    "#  |-- TotalScore2: string (nullable = true)\n",
    "#  |-- TotalScore: string (nullable = true)\n",
    "\n",
    "\n",
    "essays_human_rated = spark.read.parquet(b.file_url(WGU_File.essay_human_ratings))\\\n",
    "    .withColumnRenamed(\"EssayID\", DAACS_ID)\\\n",
    "    .join(unique_essay_ids, [DAACS_ID])\n",
    "\n",
    "\n",
    "essays_and_grades = essays_human_rated.join(wgu_ratings, [DAACS_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695b3bec-2c3e-4d7c-b936-7de26af49c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- daacs_id: integer (nullable = true)\n",
      " |-- file_name: string (nullable = true)\n",
      " |-- essay: string (nullable = true)\n",
      " |-- TotalScore1: string (nullable = true)\n",
      " |-- TotalScore2: string (nullable = true)\n",
      " |-- TotalScore: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "essays_and_grades.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8c561-85c7-4a96-9001-7028b9e58772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
